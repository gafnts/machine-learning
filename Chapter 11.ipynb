{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 11\n",
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1 Cross-validating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "features = digits.data\n",
    "target = digits.target\n",
    "\n",
    "standardizer = StandardScaler()\n",
    "logit = LogisticRegression()\n",
    "pipeline = make_pipeline(standardizer, logit)\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "cv_results = cross_val_score(\n",
    "    pipeline,\n",
    "    features, \n",
    "    target,\n",
    "    cv = kf,\n",
    "    scoring = 'accuracy',\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size = 0.1, random_state = 1\n",
    ")\n",
    "\n",
    "standardizer.fit(features_train)\n",
    "\n",
    "features_train_std = standardizer.transform(features_train)\n",
    "features_test_std = standardizer.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(standardizer, logit)\n",
    "\n",
    "cv_results = cross_val_score(\n",
    "    pipeline,\n",
    "    features,\n",
    "    target,\n",
    "    cv = kf,\n",
    "    scoring = 'accuracy',\n",
    "    n_jobs = -1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 Creating a baseline regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "features, target = boston.data, boston.target\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyRegressor(strategy='mean')\n",
    "dummy.fit(features_train, target_train)\n",
    "dummy.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "ols = LinearRegression()\n",
    "ols.fit(features_train, target_train)\n",
    "ols.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DummyRegressor(strategy='constant', constant=20)\n",
    "clf.fit(features_train, target_train)\n",
    "clf.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3 Creating a baseline classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "features, target = iris.data, iris.target\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, random_state=0\n",
    ")\n",
    "\n",
    "dummy = DummyClassifier(strategy='uniform', random_state=1)\n",
    "dummy.fit(features_train, target_train)\n",
    "dummy.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(features_train, target_train)\n",
    "classifier.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4 Evaluating binary classifier predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples = 10000,\n",
    "    n_features = 3,\n",
    "    n_informative = 3,\n",
    "    n_redundant = 0,\n",
    "    n_classes = 2,\n",
    "    random_state = 1\n",
    ")\n",
    "\n",
    "logit = LogisticRegression()\n",
    "cross_val_score(logit, X, y, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(logit, X, y, scoring = 'precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(logit, X, y, scoring = 'recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(logit, X, y, scoring = 'f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.5 Evaluating binary classifier thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target = make_classification(\n",
    "    n_samples = 10000,\n",
    "    n_features = 10,\n",
    "    n_classes = 2,\n",
    "    n_informative = 3,\n",
    "    random_state = 3\n",
    ")\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size = .1, random_state = 1\n",
    ")\n",
    "\n",
    "logit = LogisticRegression()\n",
    "logit.fit(features_train, target_train)\n",
    "target_probabilities = logit.predict_log_proba(features_test)[:, 1]\n",
    "false_positive_rate, true_positive_rate, threshold = roc_curve(target_test, target_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Receiver operating characteristic')\n",
    "plt.plot(false_positive_rate, true_positive_rate)\n",
    "plt.plot([0, 1], ls = '--')\n",
    "plt.plot([0, 0], [1, 0], c = '.7'), plt.plot([1, 1], c = '.7')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Threshold:\", threshold[116])\n",
    "print(\"True Positive Rate:\", true_positive_rate[116]) \n",
    "print(\"False Positive Rate:\", false_positive_rate[116])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Threshold:\", threshold[45])\n",
    "print(\"True Positive Rate:\", true_positive_rate[45]) \n",
    "print(\"False Positive Rate:\", false_positive_rate[45])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(target_test, target_probabilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ml39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c01ea7d99fbbbbda0ae4ef04938469e1a67b14c2d49f0fc0f5a9b425216b639"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
